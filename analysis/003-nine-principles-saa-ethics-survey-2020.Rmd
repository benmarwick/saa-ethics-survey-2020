---
title: "Draft Preliminary Report on the Survey for the Revision of the SAA's Principles of Archaeological Ethics"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2:
  number_sections: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE,
                      fig.retina = 2)
```

```{r load-pkgs}
library(tidyverse)
library(magrittr)
library(likert)
library(knitr)
library(UpSetR)
library(patchwork)

# load our custom functions
source(here::here("analysis/functions.R"))
load_survey_data()
```

# Feedback on the current nine "Principles of Archaeological Ethics" {-}

The figure below summarizes responses about the current nine "Principles of Archaeological Ethics". For each Principle, we asked "I feel that this principle and its description adequately applies to archaeological practice and its ethical challenges today." Respondents could choose one of five options along a spectrum from "Strongly Disagree" to "Strongly Agree". Figure \@ref(fig:likert-scale) shows the distribution of responses to each of those five options for each of the nine principles. We can quickly see that the principle about "Accountability" is the least applicable to current archaeological practice, with 9% of respondents. disagreeing.

---

```{r likert-scale, fig.width=10, fig.cap="Plot of responses to the individual Likert scale questions about the current nine Principles"}
# plot Likert scale items: Principles
library(grid)
  mylevels <- c('Strongly Disagree', 'Disagree', 'Neutral', 'Agree', 'Strongly Agree')
  
  output <- 
  survey_data %>% 
  select(!!likert_q) %>% 
  drop_na() %>% 
  mutate_all(~factor(., levels=mylevels)) %>% 
  as.data.frame()
  
  long_names <- names(output)
  short_names  <- str_extract(names(output), ".*\\d")
  short_principles <- 
    c("Stewardship",
      "Accountability",
      "Commercialization",
      "Public Education",
      "Intellectual Property",
      "Public Reporting",
      "Records and Preservation",
      "Training and Resources",
      "Safe Educational and Workplace"
      )
  
  names(output) <- paste0(short_names, ": ", short_principles)
  
  l_out <- likert(output)
  
plot(l_out, include.histogram = F) 

ggsave(here::here("figures/nine-principles-likert.png"),
       width = 10,
       height = 5)

```

How many people responded to these questions about the 9 principles? `r nrow(output)` people. Here's a table of how many responses in each category for each question:

```{r}
output_long <- 
  output %>% 
  pivot_longer( cols = everything(),
                names_to = "principle", 
                values_to = "response") %>% 
  group_by(principle, response) %>% 
  tally() %>% 
  pivot_wider(names_from = response, 
              values_from = n)  %>% 
  select(rev(mylevels)) %>% 
  janitor::adorn_totals("col")

write.csv(output_long,
          row.names = FALSE,
          here::here("data/derived-data/nine-principles-likert-tally.csv"))
```


---

## General observations on the current nine Principles {-}

## Text analysis on 'please elaborate' for the current nine Principles {-}

We make a network plot of co-occurrences of high-frequency words for each Principles. 

```{r}
nine_principles_elaboration <- 
survey_data %>% 
  select(contains("Please elaborate here:")) %>% 
  select("Please elaborate here:":"Please elaborate here:_8") %>% 
  rename_all(~short_principles) %>% 
  mutate(across(everything(), stringi::stri_trans_tolower))

# Word cloud
library(quanteda)

nw <- vector("list", length = ncol(nine_principles_elaboration))
for(i in 1:ncol(nine_principles_elaboration)){
  
# i <- 3
x <- nine_principles_elaboration %>% pull(i)

x_corp <- corpus(x)

set.seed(10)
dfmat1 <- dfm(x_corp,
              remove = c(stopwords("english"), 
                         "archaeological",
                         "archaeologists",
                         "archaeology",
                         "principle",
                         "saa"), 
              remove_punct = TRUE,
              remove_numbers = TRUE) %>%
   dfm_trim(min_termfreq = 5) 

df_fcm <- fcm(dfmat1)
top_fcm <- 
  fcm_select(df_fcm, 
             pattern = names(quanteda::topfeatures(dfmat1, n = 20)))
nw[[i]] <- textplot_network(top_fcm, 
                       min_freq = 0.75, 
                       edge_alpha = 0.3, 
                       edge_size = 5)
}



library(cowplot)
plot_grid(plotlist = nw)

nw[[1]]
for(i in 1:length(nw)){

ggsave(plot = nw[[i]],
       here::here(paste0("figures/nine-principles-network-principle-",
                         i, 
                         ".png")),
       width = 5,
       height = 5)

}
```

Can we get a summary of average disagreement for each demographic?

```{r}
decode_demographics()

survey_data_likert_demo <- 
bind_cols(survey_data_demographics, 
          survey_data %>% 
          select(!!likert_q, 
                 rpa = `Are you a member of the RPA?`)) %>% 
  relocate(rpa, .after = geoorigin) %>% 
  drop_na() %>% 
  filter_all(all_vars(!str_detect(., 
                                  "Prefer|other|Other")))  %>% 
  # high number == more disagree
  mutate_at(vars(!!names(survey_data)[likert_q]), 
            ~fct_rev(factor(., levels=mylevels)) ) %>% 
  mutate_at(vars(!!names(survey_data)[likert_q]), 
            ~as.numeric(.) ) 
  

# get col names
demo_cols <- c(names(survey_data_likert_demo)[1:7])
names(demo_cols) <-  
  c("Ethnicity",
    "LGBTQIA+",
    "Gender",
    "Age",
    "Country of residence",
    "Geographic origin",
    "RPA member"
  )
p_cols <- names(survey_data_likert_demo)[8:ncol(survey_data_likert_demo)]

mean_diss_out <- vector("list", length = length(p_cols))
for(i in 1:length(p_cols)){

demo_means <- 
map(demo_cols,
  ~bind_cols(
  survey_data_likert_demo[.x],
  survey_data_likert_demo[p_cols[i]]
   ) %>% 
  group_by(!!as.name(.x)) %>% 
  summarise(mean_disagreement = mean(!!as.name(p_cols[i])),
            n = n()) %>% 
  rename(var = .x)
 ) %>% 
  bind_rows(.id = "demo_var")

demo_values <- 
map(demo_cols,
  ~bind_cols(
  survey_data_likert_demo[.x],
  survey_data_likert_demo[p_cols[i]]
   ) %>% 
  rename(var = .x) 
 ) %>% 
  bind_rows(.id = "demo_var")

# https://bookdown.org/Rmadillo/likert/is-there-a-significant-difference.html
library(MASS)
library(ordinal)
library(bbmle)
library(coin)

# do a stat test for differences
xy <- 
demo_values %>% 
  mutate(li = factor(!!as.name(p_cols[i]))) %>% 
  mutate(var_fct = factor(var)) %>% 
  nest_by(demo_var) %>% 
  mutate(e_test = list(broom::tidy(kruskal.test(as.numeric(li) ~ factor(var), data = data)))) %>% 
  unnest(e_test)  %>% 
  unnest(data) %>% 
  right_join(demo_means) %>% 
  mutate(demo_var_test = paste0(demo_var, 
                                " (H(", parameter, ") = ", 
                                round(statistic, 2),
                                ", p = ", round(p.value, 3) )) 

shift_legend3 <- function(p) {
    pnls <- cowplot::plot_to_gtable(p) %>% gtable::gtable_filter("panel") %>%
      with(setNames(grobs, layout$name)) %>% purrr::keep(~identical(.x,zeroGrob()))

    if( length(pnls) == 0 ) stop( "No empty facets in the plot" )

    lemon::reposition_legend( p, "center", panel=names(pnls) )
}

mean_dis_plot <-         
ggplot(xy) +
  aes(var, 
      mean_disagreement) +
  geom_jitter(data = xy, 
                   aes(var, 
                       !!as.name(p_cols[i])),
                   alpha = 0.1
                   ) +
    geom_point(colour = "red",
               stroke = 2,
               aes(size = n,
                   shape = ifelse(p.value < 0.05, 16, 1))) +
  scale_shape_identity() +
  facet_wrap( ~ demo_var_test,
              scales = "free") +
  scale_y_continuous(limits = c(0,5), 
                     name = "Mean disagreement") +
  xlab("") +
  coord_flip() +
  theme_bw()

mean_diss_out[[i]] <- shift_legend3(mean_dis_plot)


ggsave(
  here::here(paste0("figures/nine-principles-mean-dis-", i, ".png")),
  plot = mean_diss_out[[i]] ,
       width = 15,
       height = 10)
}


```











